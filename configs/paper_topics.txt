 1. Propose new, excellent pre-trained language models, including both general-purpose models and domain-specific models. The papers should provide detailed descriptions of the model's training process, fine-tuning steps, and any novel methodologies employed.
    - Relevant: Papers that discuss and introduce new pre-trained language models, providing detailed descriptions of their performance improvements or novel methodologies. These papers should provide comprehensive information about the model's architecture, training process, and fine-tuning steps. They should explicitly discuss the advancements or improvements achieved by the proposed model compared to existing models. Additionally, relevant papers may cover novel methodologies used in the training or fine-tuning process that contribute to the model's excellence.
    - Not relevant: Papers that do not explicitly propose new pre-trained language models or only provide a high-level overview of existing models without presenting any novel, excellent models. Also, papers that focus solely on the application of pre-trained models to specific tasks without introducing any new models or significant advancements in the pre-training process would be considered not relevant.
 2. Studies 'scaling laws' in the context of neural networks. Scaling laws refer to the very clear power-law relationship between the size or computational power used to train a large language model and the performance of that model.
    - Relevant: theoretical or conceptual explanation behind scaling laws for language models.
    - Not relevant: papers that have experiments at different model scales but do not explicitly fit a scaling law.
 3. Propose advancements in modeling long-context capabilities of large language models, enabling models to effectively process and understand information from longer contexts.
    - Relevant: Papers that introduce new methods or models specifically designed to enhance a model's ability to handle long-context information. These papers should explicitly mention the model's long-context capabilities and provide detailed descriptions and empirical evidence to support their improvements. Typically, these papers may involve the utilization of position embedding mechanisms, attention mechanisms, memory mechanisms, hierarchical structures, or other innovative approaches to effectively model long-context information.
    - Not relevant: Papers that do not address improvements in long-context capabilities or only provide a general overview of the model's architecture and performance without specifically mentioning enhancements in long-context capabilities.
 4. New methodological improvements to RLHF or instruction-following which are specific fine-tuning steps that are taken to make language models better at following user instructions across a range of tasks.
    - Relevant: papers that discuss specific methods like RLHF, or instruction-tuning datasets, improving these methods, or analyzing them. Usually these papers will explicitly mention RLHF, instruction-following or instruction-tuning.
    - Not relevant: papers about adaptation to some task. Simply following instructions or inputs are not sufficient.
 5. Investigate the relationship between pre-trained language model capabilities, training data distribution, and propose improved data processing and utilization methods.
    - Relevant: Papers that specifically delve into studying the correlation between the capabilities of pre-trained language models and the characteristics of the training data distribution. These papers should explicitly discuss how different aspects of the model's performance, such as language understanding, generation quality, or domain adaptation, are influenced by the properties of the training data. They may analyze the impact of variations in data size, data domain, data diversity, or data imbalance on the model's performance. Relevant papers may propose novel metrics, evaluation methodologies, or theoretical frameworks to assess and quantify the relationship between pre-trained models and training data distribution.
    - Not relevant: Papers that do not specifically investigate the correlation between pre-trained language model capabilities and training data distribution. This includes papers that focus solely on model architectures, optimization techniques, or fine-tuning strategies without explicitly addressing the relationship with training data. Additionally, papers that explore unrelated topics or provide general overviews of pre-trained models without conducting a specific analysis of their relationship with training data distribution would be considered not relevant.
6. Studies 'training or inference speedup' in the context of neural networks. Training and Inference speedup refer to making large language models run faster during training and inference stages on different architectures like GPUs.
   - Relevant: Papers that introduce new methods to speed up training and inference process for LLMs.
   - Not revelant: Papers that do not address improvements for training or inference.
7. Studies 'model compression' in the context of neural networks. Model compression refers to compressing the large language model to a smaller size while maintaining model capability and accuracy.
   - Relevant: Papers that introduce new methods for low-bit(8bit/4bit/1bit/fp8) quantization, pruning and distillation.
   - Not relevant: Papers that do not address improvements in quantization, pruning and distillation


 In suggesting papers to your friend, remember that he enjoys papers on statistical machine learning, and generative modeling in natural language processing.
 Your friend also likes learning about surprising empirical results in language models, as well as clever statistical tricks.
 He does not want to read papers that are about primarily applications of methods to specific domains.
